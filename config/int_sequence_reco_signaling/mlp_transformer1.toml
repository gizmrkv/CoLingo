zoo = "int_sequence_reco_signaling_mlp_transformer"

n_epochs = 1001
batch_size = 100000
device = "cuda"
seed = 42
wandb_project = "int_sequence_reco_signaling"
use_tqdm = true

lr = 0.001
object_length = 2
object_n_values = 50
message_length = 8
message_n_values = 50

entropy_weight = 0.01
length_weight = 0.0

metrics_interval = 10
topsim_interval = 100
language_log_interval = 100

latent_dim = 64

object_encoder_embed_dim = 8
object_encoder_hidden_dim = 150
object_encoder_n_layers = 2
object_encoder_activation = "gelu"

message_decoder_embed_dim = 64
message_decoder_n_heads = 1
message_decoder_ff_dim = 128
message_decoder_dropout = 0.0
message_decoder_activation = "gelu"
message_decoder_layer_norm_eps = 1e-5
message_decoder_norm_first = false
message_decoder_n_layers = 1

message_encoder_embed_dim = 64
message_encoder_n_heads = 1
message_encoder_ff_dim = 128
message_encoder_dropout = 0.0
message_encoder_activation = "gelu"
message_encoder_layer_norm_eps = 1e-5
message_encoder_norm_first = false
message_encoder_n_layers = 1

object_decoder_hidden_dim = 150
object_decoder_n_layers = 2
object_decoder_activation = "gelu"
