zoo = "reco_network_mlp_transformer"

n_epochs = 10001
batch_size = 100000
device = "cuda"
seed = 42
wandb_project = "reco_network"
use_tqdm = true

lr = 0.001
object_length = 2
object_values = 30
message_max_len = 8
message_vocab_size = 50

entropy_weight = 0.01
length_weight = 0.0

metrics_interval = 10
topsim_interval = 100
language_log_interval = 100
acc_heatmap_interval = 100
lansim_interval = 100

decoder_ae = true

n_agents = 3
network_window = 3
latent_dim = 64

object_encoder_embed_dim = 8
object_encoder_hidden_dim = 64
object_encoder_n_layers = 2
object_encoder_activation = "gelu"

object_decoder_hidden_dim = 64
object_decoder_n_layers = 2
object_decoder_activation = "gelu"

message_encoder_embed_dim = 64
message_encoder_n_heads = 8
message_encoder_ff_dim = 64
message_encoder_dropout = 0.01
message_encoder_activation = "gelu"
message_encoder_layer_norm_eps = 1e-5
message_encoder_norm_first = false
message_encoder_n_layers = 2
message_encoder_is_causal = false

message_decoder_embed_dim = 64
message_decoder_n_heads = 8
message_decoder_ff_dim = 64
message_decoder_dropout = 0.01
message_decoder_activation = "gelu"
message_decoder_layer_norm_eps = 1e-5
message_decoder_norm_first = false
message_decoder_n_layers = 2
