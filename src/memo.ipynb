{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: -1.600724458694458\n",
      "Epoch 1000: -1.5607264041900635\n",
      "Epoch 2000: -1.4777616262435913\n",
      "Epoch 3000: -1.2476773262023926\n",
      "Epoch 4000: -1.4370496273040771\n",
      "Epoch 5000: -0.7159523963928223\n",
      "Epoch 6000: -0.842619776725769\n",
      "Epoch 7000: -0.7506885528564453\n",
      "Epoch 8000: -0.8220731019973755\n",
      "Epoch 9000: -1.3526273965835571\n",
      "[0, 1, 2, 0, 4]\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import itertools\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "class SimpleAgent(th.nn.Module):\n",
    "    def __init__(self, n_attributes: int, n_values: int, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.n_attributes = n_attributes\n",
    "        self.n_values = n_values\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.fc1 = th.nn.Linear(n_attributes * n_values, vocab_size)\n",
    "        self.fc2 = th.nn.Linear(vocab_size, n_attributes * n_values)\n",
    "\n",
    "    def forward(self, x: th.Tensor, input_type: str, train=True):\n",
    "        log_prob = None\n",
    "        if input_type == \"object\":\n",
    "            x = self.fc1(x)\n",
    "            x = th.nn.functional.relu(x)\n",
    "            if train:\n",
    "                dist = th.distributions.Categorical(logits=x)\n",
    "                x = dist.sample()\n",
    "                log_prob = dist.log_prob(x).mean()\n",
    "            else:\n",
    "                x = x.argmax(dim=-1)\n",
    "\n",
    "            x = th.nn.functional.one_hot(x, self.vocab_size).float()\n",
    "        elif input_type == \"message\":\n",
    "            x = self.fc2(x)\n",
    "            x = th.nn.functional.relu(x)\n",
    "\n",
    "        return x, log_prob\n",
    "\n",
    "\n",
    "N_EPOCHS = 10000\n",
    "BATCH_SIZE = 32\n",
    "N_ATTRIBUTES = 1\n",
    "N_VALUES = 4\n",
    "VOCAB_SIZE = 10\n",
    "DEVICE = \"cpu\"\n",
    "PRINT_RATE = 1000\n",
    "\n",
    "dataset = th.Tensor(\n",
    "    list(itertools.product(th.arange(N_VALUES), repeat=N_ATTRIBUTES))\n",
    ").long()\n",
    "dataset = th.nn.functional.one_hot(dataset, N_VALUES).float()\n",
    "dataset = dataset.view(-1, N_ATTRIBUTES * N_VALUES)\n",
    "dataset = dataset.to(DEVICE)\n",
    "\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "agent_1 = SimpleAgent(N_ATTRIBUTES, N_VALUES, VOCAB_SIZE).to(DEVICE)\n",
    "agent_2 = SimpleAgent(N_ATTRIBUTES, N_VALUES, VOCAB_SIZE).to(DEVICE)\n",
    "\n",
    "agent_1_optim = th.optim.Adam(agent_1.parameters(), lr=1e-3)\n",
    "agent_2_optim = th.optim.Adam(agent_2.parameters(), lr=1e-3)\n",
    "\n",
    "agent_1_baseline = 0\n",
    "agent_2_baseline = 0\n",
    "baseline_count = 0\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_reward = 0\n",
    "    baseline_count += 1\n",
    "    for batch in train_loader:\n",
    "        message, agent_1_log_prob = agent_1(batch, \"object\", train=True)\n",
    "        answer, agent_2_log_prob = agent_2(message, \"message\", train=True)\n",
    "\n",
    "        batch_size = batch.shape[0]\n",
    "        batch = batch.view(batch_size * N_ATTRIBUTES, N_VALUES)\n",
    "        answer = answer.view(batch_size * N_ATTRIBUTES, N_VALUES)\n",
    "\n",
    "        reward = -th.nn.functional.cross_entropy(answer, batch.argmax(dim=-1)).mean()\n",
    "        agent_1_baseline += (reward.detach().item() - agent_1_baseline) / baseline_count\n",
    "        agent_2_baseline += (reward.detach().item() - agent_2_baseline) / baseline_count\n",
    "\n",
    "        agent_1_loss = -agent_1_log_prob * (reward - agent_1_baseline)\n",
    "        agent_2_loss = -reward\n",
    "\n",
    "        agent_1_optim.zero_grad()\n",
    "        agent_1_loss.backward(retain_graph=True)\n",
    "        agent_1_optim.step()\n",
    "        agent_2_optim.zero_grad()\n",
    "        agent_2_loss.backward(retain_graph=True)\n",
    "        agent_2_optim.step()\n",
    "\n",
    "        total_reward += reward.item()\n",
    "\n",
    "    if epoch % PRINT_RATE == 0:\n",
    "        print(f\"Epoch {epoch}: {total_reward / len(train_loader)}\")\n",
    "\n",
    "\n",
    "message, _ = agent_1(dataset, \"object\", train=False)\n",
    "answer, _ = agent_2(message, \"message\", train=False)\n",
    "print(answer.argmax(dim=-1).view(-1, N_ATTRIBUTES, N_VALUES).squeeze().tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
